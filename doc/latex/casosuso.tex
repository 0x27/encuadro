\chapter{Casos de Uso}
\label{chap: casoUso}
\section{Introducción}
En este capítulo se presentan los distintos casos de uso que se implementaron con el fin de integrar los algoritmos comentados en capítulos anteriores en peque\~nas aplicaciones que funcionen \textit{de punta a punta}. Se buscó resolver individualmente los diferentes desafíos técnicos que una aplicación real de realidad aumentada para museos puede llegar a tener. Estas últimas no serán más que una combinación guionada de cada uno de estos casos de uso.\\

A lo cargo del capítulo se verán entonces los tres casos de uso implementados: ``interactividad'', ``video'' y ``modelos''. El primero presenta un modelo simple sobre el marcador que responde a toques con cierto movimiento y un audio en particular, el segundo soluciona el problema de proyectar un video sobre el marcador de forma consistente con el movimiento del usuario. El último caso de uso muestra cómo es posible importar modelos a ISGL3D de manera de lograr realidades aumentadas mucho más interesantes que si tan sólo se hicieran con las primitivas del \textit{framework}, por detalles ver capítulo \ref{chap: render}.

\section{Caso de uso ``interactividad''}
\label{sec: casoUso1}
\subsection{Comentarios sobre el caso de uso}
En este caso de uso se implementa la parte interactiva de la aplicación. Al enfocar el marcador, se puede ver un cubo sobre el QlSet de la esquina superior izquierda. Ver Figura \ref{fig:CasoUso1}. Si el cubo es tocado a través de la pantalla del dispositivo, este se anima y se reproduce un audio que indica la posición del cubo en el instante de ser presionado. Inmediatamente después, es desplazado hacia el QlSet de la esquina superior derecha. Nuevamente, si el cubo es tocado a través de la pantalla del dispositivo, este se anima y se reproduce un audio que indica la posición del cubo en el instante de ser presionado. Inmediatamente después, este se desplaza hacia el QlSet restante. Lo anterior sucederá de forma cíclica, cada vez que se presione sobre el mpdelo.\\ 

Esta funcionalidad es fundamental si lo que se quiere implementar es por ejemplo una audioguía interactiva. Podría pensarse una aplicación en la que el cubo anterior se reemplace por flechas 3D, y que estas sean ubicadas conjuntamente en distintas partes de una obra. Entones, al seleccionar cada una de las flechas, se podría reproducir un audio con información referente a esa zona o punto en particular.\\ 


\begin{figure}[h!]
\centering
\includegraphics[scale=0.3]{figs_casosuso/CasoUso1}
\caption{Captura de pantalla del caso de uso ``interactividad'', se puede ver el cubo apoyado sobre el QlSet de la esquina superior izquierda y los diferentes controles que ayudan a la depuración del código.}
\label{fig:CasoUso1}
\end{figure}

Esta aplicación también se utilizó con fines de \textit{debugging} o depuración de la integración de cada uno de los bloques. Se le agregaron las siguientes funcionalidades:
\begin{itemize}
\item[$\bullet$] La posibilidad de ver dibujados sobre la imagen los segmentos detectados por LSD. En sus versiones original y opimizada.
\item[$\bullet$] La posibilidad de ver dibujados sobre la imagen los segmentos filtrados pertenecientes al marcador. Así como también las esquinas detectadas de cada uno de los cuadriláteros que lo forman.
\item[$\bullet$] La posibilidad de variar el umbral utilizado para el filtrado de segmentos. 
\item[$\bullet$] La posibilidad de ver las esquinas de cada uno de los cuadriláteros que forman al marcador reproyectadas según la pose del dispositivo obtenida.
\item[$\bullet$] La posibilidad de prender o apagar el filto de Kalman.
\item[$\bullet$] La posibilidad de aumentar o disminuir el ruido de medición del filtro de Kalman.
\item[$\bullet$] La posibilidad de elegir si usar o no la fusión de la estimación de pose con los sensores. 
\end{itemize} 

%\begin{figure}[h!]
%\centering
%\includegraphics[scale=0.35]{figs_casosuso/CasoUso1ini}
%\caption{Pantalla inicial de caso de uso 1, en esta pantalla se explica como funciona la interfaz de usuario }
%\label{fig:CasoUso1ini}
%\end{figure}



En la Figura \ref{fig:CasoUso1} también se puede ver cómo es la interfaz de usuario de este caso de uso, en donde se puede elegir entre todas las funcionalidades anteriores. El mismo fue fundamental para evaluar el desempe\~no de los algoritmos utilizados funcionando en tiempo real. Gracias a estas funcionalidades se pudieron definir las condiciones para las cuales el conjunto de todos los bloques funciona mejor. Se fue variando la distancia al marcador y se ajustó el umbral para el filtro de segmentos. Además, se pudieron ajustar los parámetros del filtro de Kalman y se pudo comparar el desempe\~no de la estimación de pose utilizando solamente información de la cámara con el resultado obtenido de la fusión de sensores. Fue en este caso de uso que se evaluó cualitativamente el desempe\~no de la versión optimizada de LSD, respecto del de la versión original. \\

Si bien todas estas pruebas y ajustes si hicieron previamente en una computadora y con imágenes de prueba, fue necesario contar con una aplicación en la que se pudiera ver sobre el dispositivo al conjunto de los algoritmos funcionando en tiempo real.  
\subsection{Detalles constructivos}
Explicar clase dibujar, touch event y reproducir audio. 

\section{Caso de uso ``video''}
\subsection{Comentarios sobre el caso de uso}
Este caso de uso básicamente busca desplegar un video en una superfice dada del mundo real. Esto puede ser de gran interés como complemento de contenido para un cuadro o cualquier obra si se piensa en aplicarlo para museos. Es posible por ejemplo, generar un video que sea reproducido dentro de los marcos del propio cuadro, en un extremo o en una superficie cualquiera que resulte interesante desde el punto de vista artístico. A continuación se explican brevemente algunos detalles para lograr la implementación de este caso de uso.
\\
PONER FOTO MOSTRANDO EL CASO DE USO CON VIDEO PROYECTADO.\\
\subsection{Detalles constructivos}
Para lograr lo propuesto para este caso de uso se implementó un proyecto que proyecta el video en uno de los cuadrados del marcador. De esta manera, de toda la lógica de estimación de pose, solamente se hace uso de la detección y filtrado. En particular no se hace uso de los resultados del posit. Teniendo entonces detectados los cuatro puntos en los que se quiere reproducir el video parecería que el problema está resuelto. Sin embargo, xcode no permite posicionar en forma directa una vista de video en cualquier conjunto de cuatro puntos. \\
Si simplemente se quiere reproducir un video, y no se quiere procesar el contenido, lo más cómodo para hacerlo es utilizar la clase \textit{MPMoviePlayerController} que hereda de \textit{NSObject}. Una alternativa similar es haciendo uso de la clase \textit{MPMoviePlayerViewController} que hereda de \textit{UIViewController} y tiene como única propiedad una del tipo \textit{MPMoviePlayerController}. \\
\textit{MPMoviePlayerController} tiene un atributo \textit{view} del tipo \textit{UIView} que es la vista y es este atributo el que se quiere posicionar en los cuatro puntos detectados por el filtro. Un atributo del tipo \textit{UIView} tiene un atributo \textit{frame} que es del tipo \textit{CGRect}
\begin{verbatim}
theMovie.view.frame = CGRectMake(0, 0, 60, 60);
\end{verbatim}
En el código anterior \textit{theMovie} es del tipo \textit{MPMoviePlayerController}. De esta manera, se tiene el inconveniente de que en principio cualquier video parecería que solamente puede ser reproducido sobre rectángulos y no en cualquier polígono de cuatro puntos por ejemplo. Sin embargo algo que sí se puede hacer a las instancias de la clase \textit{UIView} es una transformación afin o incluso, de manera más genérica, una homografía. 
\subsection{\textit{CGAffineTransform} y \textit{CATransform3D}}
La clase \textit{UIView} tiene una propiedad llamada \textit{transform} que es del tipo \textit{CGAffineTransform}. Las primeras letras de esta clase  (\textit{CG}) refieren a la API \textbf{Core Graphics} utilizada ampliamente como herramienta para resolver \textit{rendering} y cualquier tipo de transformación en 2D.\\
La clase \textit{UIView} también tiene una propiedad llamada \textit{layer} que es del tipo \textit{CALayer} y que permite realizar transformaciones del tipo	 \textit{CATransform3D}. Las primeras letras de estas dos clases  (\textit{CA}) refieren a la API \textbf{Core Animation} que es utilizada para generar animaciones y transformaciones sobre objetos 3D solamente indicando un punto inicial y final para el objeto (también es posible agregar efectos para la transición). En definitiva para resolver el problema del caso de uso existen a priori dos alternativas posibles: \textit{CGAffineTransform} y \textit{CATransform3D}.\\
Se pueden generar fácilmente instancias transformaciones afines invocando la siguiente función:
\begin{verbatim}
CGAffineTransform CGAffineTransformMake (
   CGFloat a,
   CGFloat b,
   CGFloat c,
   CGFloat d,
   CGFloat tx,
   CGFloat ty
);
\end{verbatim}
que toma 6 \textit{CGFloats} y crea una \textit{CGAffineTransform}, donde cada uno de los valores anteriores se corresponde con los elementos de una matriz transformación afín de la siguiente manera:
\[
\left( \begin{array}{ccc}
a & b & 0 \\ 
c & d & 0 \\
t_{x} & t_{y} & 1 
\end{array} \right)
\]
Así entonces, de los 9 valores de la matriz, 2 de ellos son nulos por tratarse de una transformación afín y otro de ellos es unitario como valor de escala. Resolviendo el sistema como se muestra en la sección \ref{sec: resHomo} y obteniendo los restantes 6 valores, se le puede asignar transformaciones a la propiedad \textit{transform} y realizar la trasnformación deseada. Este método tuvo como inconveniente el hecho de que .....
\\
EXPLICAR POR QUE NO FUNCIONÓ
\\
Por su parte también es sencillo generar instancias de transformaciones 3D debido a que existe el tipo de dato definido para generar la matriz \textit{CATransform3D} como:
\begin{verbatim}
struct CATransform3D
{
CGFloat m11, m12, m13, m14;
CGFloat m21, m22, m23, m24;
CGFloat m31, m32, m33, m34;
CGFloat m41, m42, m43, m44;
};
typedef struct CATransform3D CATransform3D;
\end{verbatim}
donde $m_{ij}$ corresponde al elemento de la matriz ubicado en la fila $i$ columna $j$. Así entonces también es posible, conociendo los valores de la homografía, completar los elementos de esta matriz 4x4 y asignársela a la propiedad \textit{layer} de la \textit{UIView}. Esta opción de generar una transformación 3D permite incluir transformaciones más generales que una homografía o una transformación afín. Si lo que se busca es que esta matriz represente una homografía (2D), es necesario entonces que la coordenada z sea nula, es decir
\[
\left( \begin{array}{cccc}
m_{11} & m_{12} &    0   & m_{14}\\ 
m_{21} & m_{22} &    0   & m_{24}\\
   0   &    0   &    1   &    0  \\
m_{41} & m_{42} &    0   & m_{44}
\end{array} \right)
\]
donde a su vez $m_{44}$ se asume de valor unitario por ser un factor de escala. De la misma manera que para la transformación afín, resolviendo la homografía como se ve en la sección \ref{sec: resHomo} se obtienen los 8 valores restantes de la matriz y es posible asignarle una homografía a un objeto \textit{UIView} para resolver el problema presente.

\subsection{Resolución de Homografía}
\label{sec: resHomo}
A continuación se hace el desarrollo de la resolución del sistema de ecuaciones que se tuvo que resolver para hallar los parámetros de la homografía que transforma una imagen de referencia en la imagen que se tiene en cada momento como resultado de la captura de la cámara. Se asume entonces que se conocen los puntos de referencia y los puntos de referencia transformados (los detectados luego del filtrado de segmentos) y lo que se quiere averiguar es la matriz $h$ que logra dicha transformación. Esta homografía 2D-2D se puede expresar en forma matricial, en coordenadas homogéneas de la siguiente manera:
\[
\left( \begin{array}{ccc}
h_{11} & h_{12} & h_{13} \\ 
h_{21} & h_{22} & h_{23} \\
h_{31} & h_{32} & h_{33} 
\end{array} \right)
\left( \begin{array}{c}
x \\ 
y \\
z
\end{array} \right)
=
\left( \begin{array}{c}
i \\
j \\
k
\end{array} \right)
\]
donde la matriz $h_{3x3}$  representa la transformación homográfica, el vector $(x,y,z)^t$  representa los puntos de referencia a ser transformados y el vector $(i,j,k)^t$  respresenta los puntos detectados cuadro a cuadro como las esquinas del marcador.\\
Asumiendo un valor unitario para las coordenadas $z$ y $k$ la resolución del sistema se simplifica mucho y no se pierde generalidad. Imponiendo esto entonces, el sistema anterior se puede expresar de la siguiente forma:
\begin{equation}\label{eq_1}
xh_{11} + yh_{12} + h_{13} = i
\end{equation}
\begin{equation}\label{eq_2}
xh_{21} + yh_{22} + h_{23} = j
\end{equation}
\begin{equation}\label{eq_3}
xh_{31} + yh_{32} + h_{33} = 1
\end{equation}
Multiplicando la ecuación \eqref{eq_3} por $i$ e igualándola a la ecuación \eqref{eq_1} se obtiene lo siguiente:
\begin{equation}
xh_{11} + yh_{12} + h_{13} = ixh_{31} + iyh_{32} + ih_{33}
\end{equation}
o lo que es lo mismo:
\begin{equation}\label{eq_4}
xh_{11} + yh_{12} + h_{13} - ixh_{31} - iyh_{32} - ih_{33}=0
\end{equation}
Procediendo de manera análoga y multiplicando la ecuación \eqref{eq_3} por $j$ e igualándola a la ecuación \eqref{eq_2} se obtiene lo siguiente:
\begin{equation}
xh_{21} + yh_{22} + h_{23} = jxh_{31} + jyh_{32} + jh_{33}
\end{equation}
o lo que es lo mismo:
\begin{equation}\label{eq_4}
xh_{21} + yh_{22} + h_{23} - jxh_{31} - jyh_{32} - jh_{33}=0
\end{equation}
Las ecuaciones \eqref{eq_3} y \eqref{eq_4} se pueden expresar en forma matricial, de la siguiente manera:
\[
\left( \begin{array}{ccccccccc}
x & y & 1 & 0 & 0 & 0 & -ix & -iy & -i \\ 
0 & 0 & 0 & x & y & 1 & -jx & -jy & -j
\end{array} \right)
\left( \begin{array}{ccccccccc}
h_{11} \\ 
h_{12} \\
h_{13} \\
h_{21} \\
h_{22} \\
h_{23} \\
h_{31} \\
h_{32} \\
h_{33}
\end{array} \right)
=
\left( \begin{array}{ccccccccc}
0 \\ 
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
0
\end{array} \right)
\]
Teniendo entonces 4 parejas de puntos referencia y puntos transformados y asumiendo $h_{33}$ de valor unitario se tiene entonces 8 ecuaciones y 8 incógnitas, lo que lo vuelve un sistema compatible determinado que se puede expresar de la siguiente manera:
\[
\left( \begin{array}{cccccccc}
x_0 & y_0 & 1 &  0  &  0  & 0 & -i_0x_0 & -i_0y_0 \\ 
0   &  0  & 0 & x_0 & y_0 & 1 & -j_0x_0 & -j_0y_0 \\

x_1 & y_1 & 1 &  0  &  0  & 0 & -i_1x_1 & -i_1y_1 \\ 
0   &  0  & 0 & x_1 & y_1 & 1 & -j_1x_1 & -j_1y_1 \\

x_2 & y_2 & 1 &  0  &  0  & 0 & -i_2x_2 & -i_2y_2 \\ 
0   &  0  & 0 & x_2 & y_2 & 1 & -j_2x_2 & -j_2y_2 \\

x_3 & y_3 & 1 &  0  &  0  & 0 & -i_3x_3 & -i_3y_3 \\ 
0   &  0  & 0 & x_3 & y_3 & 1 & -j_3x_3 & -j_3y_3  

\end{array} \right)
\left( \begin{array}{cccccccc}
h_{11} \\ 
h_{12} \\
h_{13} \\
h_{21} \\
h_{22} \\
h_{23} \\
h_{31} \\
h_{32} 
\end{array} \right)
=
\left( \begin{array}{cccccccc}
i_0 \\ 
j_0 \\
i_1 \\
j_1 \\
i_2 \\
j_2 \\
i_3 \\
j_3
\end{array} \right)
\]
Así entonces, lo que se hace para resolver la homografía es cuadro a cuadro tener detectados los puntos en los que se quiere presentar la vista del video que se corresponden con cuatro puntos detectados por el filtro y tener las correspondencias con el marcador real, se posiciona la vista en la posición de referencia y se le aplica la homografía hallada que vincula la posición referencia con los puntos detectados.
\section{Caso de uso ``modelos''}
\subsection{Comentarios sobre el caso de uso}
\subsection{Detalles constructivos}
