\chapter{Casos de Uso}
\label{chap: casoUso}
\section{Introducción}
En este capítulo se describen los distintos casos de uso que se implementaron con el fin de aplicar los algoritmos desarrollados en los capítulos anteriores. Se buscó generar distintos casos de uso que funcionaran como muestra de las funcionalidades que son posibles de realizar mediante la resolución de los algoritmos mencionados.
\section{Caso de Uso 01}
\subsection{Comentarios sobre el caso de uso}
En este caso de uso implementa la parte interactiva de la aplicación. Cuando inicia la aplicación se ve un cubo sobre uno de los marcadores, cuando se presiona sobre el cubo, este se anima y se reproduce un audio. Luego el cubo pasa a estar sobre otro marcador. Esta funcionalidad es fundamental para implementar la audioguía interactiva, podría pensarse una aplicación en la que se presione sobre determinada parte de un cuadro y se reproduzca un audio con información referente a esa zona. 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.35]{figs_casosuso/CasoUso1ini}
\caption{Pantalla inicial de caso de uso 1, en esta pantalla se explica como funciona la interfaz de usuario }
\label{fig:CasoUso1ini}
\end{figure}

Esta aplicación también se utilizo con fines de \textit{debugging}. Se tienen las siguientes funcionalidades:
\begin{itemize}
\item[$\bullet$] Se puede ver dibujada sobre la imagen la salida del LSD.
\item[$\bullet$] Se puede ver dibujada sobre la imagen la salida del filtro de segmentos y correspondencias.
\item[$\bullet$] Se puede variar el umbral utilizado para el filtro de segmentos. 
\item[$\bullet$] Se pueden ver los puntos del modelo reproyectados según la pose obtenida.
\item[$\bullet$] Se puede prender o apagar Kalman.
\item[$\bullet$] Se puede aumentar o disminuir el ruido de medición del filtro de Kalman.
\item[$\bullet$] Se puede elegir si se usa o no la fusión de sensores. 
\end{itemize} 

\begin{figure}[h!]
\centering
\includegraphics[scale=0.35]{figs_casosuso/CasoUso1}
\caption{Captura de pantalla del caso de uso 1, se puede ver el cubo apoyado sobre el marcador y los diferentes controles que ayudan al \textit{debugging}}
\label{fig:CasoUso1}
\end{figure}

En la Figura \ref{fig:CasoUso1ini} se puede ver como es la interfaz de usuario de esta aplicación y en la Figura \ref{fig:CasoUso1} una captura de pantalla. Esta aplicación fue fundamental para evaluar el desempe\~no de los algoritmos utilizados. Gracias a estas funcionalidades se pudo definir el ambiente bajo el cual la aplicación funciona, se fue variando la distancia al marcador y se ajustó el umbral para el filtro de segmentos. 
Se pudo ajustar los parámetros del filtro de Kalman y se pudo comparar el desempe\~no de la estimación de pose utilizando solamente información de la cámara con el resultado obtenido de la fusión de sensores. 
Se pudo evaluar también el desempe\~n de la versión optimizada de LSD. 
Si bien todas estas pruebas y ajustes si hicieron previamente en una computadora con imágenes de prueba, fue necesario contar con una aplicación en la que se pudiera ver sobre el dispositivo el comportamiento en tiempo real.  
\subsection{Detalles constructivos}
Explicar clase dibujar, touch event y reproducir audio. 
\section{Caso de Uso 02}
\subsection{Comentarios sobre el caso de uso}
Este caso de uso básicamente busca desplegar un video en una superfice dada del mundo real. Esto puede ser de gran interés como complemento de contenido para un cuadro o cualquier obra si se piensa en aplicarlo para museos. Es posible por ejemplo, generar un video que sea reproducido dentro de los marcos del propio cuadro, en un extremo o en una superficie cualquiera que resulte interesante desde el punto de vista artístico. A continuación se explican brevemente algunos detalles para lograr la implementación de este caso de uso.
\\
PONER FOTO MOSTRANDO EL CASO DE USO CON VIDEO PROYECTADO.\\
\subsection{Detalles constructivos}
Para lograr lo propuesto para este caso de uso se implementó un proyecto que proyecta el video en uno de los cuadrados del marcador. De esta manera, de toda la lógica de estimación de pose, solamente se hace uso de la detección y filtrado. En particular no se hace uso de los resultados del posit. Teniendo entonces detectados los cuatro puntos en los que se quiere reproducir el video parecería que el problema está resuelto. Sin embargo, xcode no permite posicionar en forma directa una vista de video en cualquier conjunto de cuatro puntos. \\
Si simplemente se quiere reproducir un video, y no se quiere procesar el contenido, lo más cómodo para hacerlo es utilizar la clase \textit{MPMoviePlayerController} que hereda de \textit{NSObject}. Una alternativa similar es haciendo uso de la clase \textit{MPMoviePlayerViewController} que hereda de \textit{UIViewController} y tiene como única propiedad una del tipo \textit{MPMoviePlayerController}. \\
\textit{MPMoviePlayerController} tiene un atributo \textit{view} del tipo \textit{UIView} que es la vista y es este atributo el que se quiere posicionar en los cuatro puntos detectados por el filtro. Un atributo del tipo \textit{UIView} tiene un atributo \textit{frame} que es del tipo \textit{CGRect}
\begin{verbatim}
theMovie.view.frame = CGRectMake(0, 0, 60, 60);
\end{verbatim}
En el código anterior \textit{theMovie} es del tipo \textit{MPMoviePlayerController}. De esta manera, se tiene el inconveniente de que en principio cualquier video parecería que solamente puede ser reproducido sobre rectángulos y no en cualquier polígono de cuatro puntos por ejemplo. Sin embargo algo que sí se puede hacer a las instancias de la clase \textit{UIView} es una transformación afin o incluso, de manera más genérica, una homografía. 
\subsection{\textit{CGAffineTransform} y \textit{CATransform3D}}
La clase \textit{UIView} tiene una propiedad llamada \textit{transform} que es del tipo \textit{CGAffineTransform}. Las primeras letras de esta clase  (\textit{CG}) refieren a la API \textbf{Core Graphics} utilizada ampliamente como herramienta para resolver \textit{rendering} y cualquier tipo de transformación en 2D.\\
La clase \textit{UIView} también tiene una propiedad llamada \textit{layer} que es del tipo \textit{CALayer} y que permite realizar transformaciones del tipo	 \textit{CATransform3D}. Las primeras letras de estas dos clases  (\textit{CA}) refieren a la API \textbf{Core Animation} que es utilizada para generar animaciones y transformaciones sobre objetos 3D solamente indicando un punto inicial y final para el objeto (también es posible agregar efectos para la transición). En definitiva para resolver el problema del caso de uso existen a priori dos alternativas posibles: \textit{CGAffineTransform} y \textit{CATransform3D}.\\
Se pueden generar fácilmente instancias transformaciones afines invocando la siguiente función:
\begin{verbatim}
CGAffineTransform CGAffineTransformMake (
   CGFloat a,
   CGFloat b,
   CGFloat c,
   CGFloat d,
   CGFloat tx,
   CGFloat ty
);
\end{verbatim}
que toma 6 \textit{CGFloats} y crea una \textit{CGAffineTransform}, donde cada uno de los valores anteriores se corresponde con los elementos de una matriz transformación afín de la siguiente manera:
\[
\left( \begin{array}{ccc}
a & b & 0 \\ 
c & d & 0 \\
t_{x} & t_{y} & 1 
\end{array} \right)
\]
Así entonces, de los 9 valores de la matriz, 2 de ellos son nulos por tratarse de una transformación afín y otro de ellos es unitario como valor de escala. Resolviendo el sistema como se muestra en la sección \ref{sec: resHomo} y obteniendo los restantes 6 valores, se le puede asignar transformaciones a la propiedad \textit{transform} y realizar la trasnformación deseada. Este método tuvo como inconveniente el hecho de que .....
\\
EXPLICAR POR QUE NO FUNCIONÓ
\\
Por su parte también es sencillo generar instancias de transformaciones 3D debido a que existe el tipo de dato definido para generar la matriz \textit{CATransform3D} como:
\begin{verbatim}
struct CATransform3D
{
CGFloat m11, m12, m13, m14;
CGFloat m21, m22, m23, m24;
CGFloat m31, m32, m33, m34;
CGFloat m41, m42, m43, m44;
};
typedef struct CATransform3D CATransform3D;
\end{verbatim}
donde $m_{ij}$ corresponde al elemento de la matriz ubicado en la fila $i$ columna $j$. Así entonces también es posible, conociendo los valores de la homografía, completar los elementos de esta matriz 4x4 y asignársela a la propiedad \textit{layer} de la \textit{UIView}. Esta opción de generar una transformación 3D permite incluir transformaciones más generales que una homografía o una transformación afín. Si lo que se busca es que esta matriz represente una homografía (2D), es necesario entonces que la coordenada z sea nula, es decir
\[
\left( \begin{array}{cccc}
m_{11} & m_{12} &    0   & m_{14}\\ 
m_{21} & m_{22} &    0   & m_{24}\\
   0   &    0   &    1   &    0  \\
m_{41} & m_{42} &    0   & m_{44}
\end{array} \right)
\]
donde a su vez $m_{44}$ se asume de valor unitario por ser un factor de escala. De la misma manera que para la transformación afín, resolviendo la homografía como se ve en la sección \ref{sec: resHomo} se obtienen los 8 valores restantes de la matriz y es posible asignarle una homografía a un objeto \textit{UIView} para resolver el problema presente.

\subsection{Resolución de Homografía}
\label{sec: resHomo}
A continuación se hace el desarrollo de la resolución del sistema de ecuaciones que se tuvo que resolver para hallar los parámetros de la homografía que transforma una imagen de referencia en la imagen que se tiene en cada momento como resultado de la captura de la cámara. Se asume entonces que se conocen los puntos de referencia y los puntos de referencia transformados (los detectados luego del filtrado de segmentos) y lo que se quiere averiguar es la matriz $h$ que logra dicha transformación. Esta homografía 2D-2D se puede expresar en forma matricial, en coordenadas homogéneas de la siguiente manera:
\[
\left( \begin{array}{ccc}
h_{11} & h_{12} & h_{13} \\ 
h_{21} & h_{22} & h_{23} \\
h_{31} & h_{32} & h_{33} 
\end{array} \right)
\left( \begin{array}{c}
x \\ 
y \\
z
\end{array} \right)
=
\left( \begin{array}{c}
i \\
j \\
k
\end{array} \right)
\]
donde la matriz $h_{3x3}$  representa la transformación homográfica, el vector $(x,y,z)^t$  representa los puntos de referencia a ser transformados y el vector $(i,j,k)^t$  respresenta los puntos detectados cuadro a cuadro como las esquinas del marcador.\\
Asumiendo un valor unitario para las coordenadas $z$ y $k$ la resolución del sistema se simplifica mucho y no se pierde generalidad. Imponiendo esto entonces, el sistema anterior se puede expresar de la siguiente forma:
\begin{equation}\label{eq_1}
xh_{11} + yh_{12} + h_{13} = i
\end{equation}
\begin{equation}\label{eq_2}
xh_{21} + yh_{22} + h_{23} = j
\end{equation}
\begin{equation}\label{eq_3}
xh_{31} + yh_{32} + h_{33} = 1
\end{equation}
Multiplicando la ecuación \eqref{eq_3} por $i$ e igualándola a la ecuación \eqref{eq_1} se obtiene lo siguiente:
\begin{equation}
xh_{11} + yh_{12} + h_{13} = ixh_{31} + iyh_{32} + ih_{33}
\end{equation}
o lo que es lo mismo:
\begin{equation}\label{eq_4}
xh_{11} + yh_{12} + h_{13} - ixh_{31} - iyh_{32} - ih_{33}=0
\end{equation}
Procediendo de manera análoga y multiplicando la ecuación \eqref{eq_3} por $j$ e igualándola a la ecuación \eqref{eq_2} se obtiene lo siguiente:
\begin{equation}
xh_{21} + yh_{22} + h_{23} = jxh_{31} + jyh_{32} + jh_{33}
\end{equation}
o lo que es lo mismo:
\begin{equation}\label{eq_4}
xh_{21} + yh_{22} + h_{23} - jxh_{31} - jyh_{32} - jh_{33}=0
\end{equation}
Las ecuaciones \eqref{eq_3} y \eqref{eq_4} se pueden expresar en forma matricial, de la siguiente manera:
\[
\left( \begin{array}{ccccccccc}
x & y & 1 & 0 & 0 & 0 & -ix & -iy & -i \\ 
0 & 0 & 0 & x & y & 1 & -jx & -jy & -j
\end{array} \right)
\left( \begin{array}{ccccccccc}
h_{11} \\ 
h_{12} \\
h_{13} \\
h_{21} \\
h_{22} \\
h_{23} \\
h_{31} \\
h_{32} \\
h_{33}
\end{array} \right)
=
\left( \begin{array}{ccccccccc}
0 \\ 
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
0 \\
0
\end{array} \right)
\]
Teniendo entonces 4 parejas de puntos referencia y puntos transformados y asumiendo $h_{33}$ de valor unitario se tiene entonces 8 ecuaciones y 8 incógnitas, lo que lo vuelve un sistema compatible determinado que se puede expresar de la siguiente manera:
\[
\left( \begin{array}{cccccccc}
x_0 & y_0 & 1 &  0  &  0  & 0 & -i_0x_0 & -i_0y_0 \\ 
0   &  0  & 0 & x_0 & y_0 & 1 & -j_0x_0 & -j_0y_0 \\

x_1 & y_1 & 1 &  0  &  0  & 0 & -i_1x_1 & -i_1y_1 \\ 
0   &  0  & 0 & x_1 & y_1 & 1 & -j_1x_1 & -j_1y_1 \\

x_2 & y_2 & 1 &  0  &  0  & 0 & -i_2x_2 & -i_2y_2 \\ 
0   &  0  & 0 & x_2 & y_2 & 1 & -j_2x_2 & -j_2y_2 \\

x_3 & y_3 & 1 &  0  &  0  & 0 & -i_3x_3 & -i_3y_3 \\ 
0   &  0  & 0 & x_3 & y_3 & 1 & -j_3x_3 & -j_3y_3  

\end{array} \right)
\left( \begin{array}{cccccccc}
h_{11} \\ 
h_{12} \\
h_{13} \\
h_{21} \\
h_{22} \\
h_{23} \\
h_{31} \\
h_{32} 
\end{array} \right)
=
\left( \begin{array}{cccccccc}
i_0 \\ 
j_0 \\
i_1 \\
j_1 \\
i_2 \\
j_2 \\
i_3 \\
j_3
\end{array} \right)
\]
Así entonces, lo que se hace para resolver la homografía es cuadro a cuadro tener detectados los puntos en los que se quiere presentar la vista del video que se corresponden con cuatro puntos detectados por el filtro y tener las correspondencias con el marcador real, se posiciona la vista en la posición de referencia y se le aplica la homografía hallada que vincula la posición referencia con los puntos detectados.
\section{Caso de Uso 03}
\subsection{Comentarios sobre el caso de uso}
\subsection{Detalles constructivos}
\section{Caso de Uso 04}
\subsection{Comentarios sobre el caso de uso}
\subsection{Detalles constructivos}
