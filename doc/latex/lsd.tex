\chapter{LSD: ``Line Segment Detection''}

\section{Introducción}
LSD es un algoritmo de detección de segmentos publicado por Rafael Grompone von Gioi, Jérémie Jakubowicz, Jean-Michel Morel y Gregory Randall en abril de 2010. Es temporalmente lineal, tiene presición inferior a un píxel y no requiere de un tuneo previo de parámetros, como casi todos los demás algoritmos de idéntica función; puede ser considerado el estado del arte en cuanto a detección de segmentos en imágenes digitales. Como cualquier otro algoritmo de detección de segmentos, LSD basa su estudio en la búsqueda de contornos angostos dentro de la imagen. Estos son regiones en donde el nivel de brillo de la imagen cambia notoriamente entre píxeles vecinos, por lo que el gradiente de la misma resulta de vital importancia. Se genera previo al análisis de la imagen, un campo de orientaciones asociadas a cada uno de los píxeles denominado por los autores \textit{level-line orientation field}. Dicho campo se obtiene de calcular las orientaciones ortogonales a los ángulos asociados al gradiente del la imagen. Luego, LSD puede verse como una composición de tres pasos:\\
\begin{itemize}
\item[(1)] División de la imagen en las llamadas \textit{line-support regions}, que son grupos conexos de píxeles con idéntica orientación, hasta cierta tolerancia. 
\item[(2)] Búsqueda del segmento que mejor aproxime cada  \textit{line-support region}: aproximación de las regiones por rectángulos.
\item[(3)] Validación o no de cada segmento detectado en el punto anterior. 
\end{itemize}
Los puntos (1) y (2) están basados en el algoritmo de detección de segmentos de Burns, Hanson y Riseman y el punto (3) es una adaptación del método \textit{a contrario} de Desolneux, Moisan y Morel. 

\section{\textit{Line-support regions}}
El primer paso de LSD es el dividir la imagen en regiones conexas de píxeles con igual orientación, a menos de cierta tolerancia $\tau$, llamadas \textit{line-support regions}. El método para realizar tal división es del tipo ``región creciente''; cada región comienza por un píxel y cierto ángulo asociado, que en este caso coincide con el de este primer píxel. Luego, se testean sus ocho vecinos y los que cuenten con un ángulo similar al de la región son incluídos en la misma. En cada iteración el ángulo asociado a la región es calculado como el promedio de las orientaciones de cada píxel dentro de la \textit{line-support region}; la iteración termina cuando ya no se pueden agregar más píxeles a esta.\\

\begin{figure}[h!]
\centering
\includegraphics[scale=0.2]{figs_lsd/lsd_1.eps}
\caption{Proceso de crecimiento de una región. El ángulo asociado cada píxel de la imagen está representado por los peque\~nos segmentos y los píxeles coloreados representan la formación de la región. Fuente \cite{grompone10}.}
\label{fig: lsd_1}
\end{figure}

Los píxels agregados a una región son marcados de manera que no vuelvan a ser testeados. Para mejorar el desempe\~no del algoritmo, las regiones comienzan a evaluarse por los píxeles con gradientes de mayor amplitud ya que estos representan mejor los bordes. \\
Existen algunos casos puntuales en los que el proceso de búsqueda de \textit{line-support regions} puede arrojar errores. Por ejemplo, cuando se tienen dos segmentos que se juntan y que son colineales a no ser por la tolerancia $\tau$ descripta anteriormente, se detectarán ambos segmentos como uno solo; ver figura \ref{fig: lsd_2}. Este potencial problema es heredado del algoritmo de Burns, Hanson y Riseman.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.25]{figs_lsd/lsd_2.eps}
\caption{Potencial problema heredado del algoritmo de Burns, Hanson y Riseman. Izq.: Imagen original. Ctro.: Segmento detectado. Der.: Segmentos que deberían haberse detectado. Fuente \cite{grompone10}.}
\label{fig: lsd_2}
\end{figure}

Sin embargo, LSD plantea un método para ahorraste este tipo de problemas. Durante el proceso de crecimiento de las regiones, también se realiza la aproximación rectangular a dicha región (paso (2) de los tres definidos anteriormente); y si menos del $50\%$ de los píxeles dentro del rectángulo corresponden a la \textit{line-support region}, entonces lo que se tiene no es un segmento. Se detiene entonces el crecimiento de la región.

\section{Aproximación de las regiones por rectángulos}

\begin{figure}[h!]
\centering
\includegraphics[scale=0.2]{figs_lsd/lsd_3.eps}
\caption{Búsqueda del segmento que mejor aproxime cada \textit{line-support region}: aproximación de una región por un rectángulo. Izq.: Imagen original. Ctro.: Una de las regiones computadas. Der.: Aproximación rectangular que cubre el $99\%$ de la masa de la región. Fuente \cite{grompone10}.}
\label{fig: lsd_3}
\end{figure}

Cada \textit{line-support region} debe ser asociada a un segmento. Cada segmento será determinado por su centro, su dirección, su anchura y su longitud. A diferencia de lo que pudiése dictar la intuición, la dirección asociada al segmento no se corresponde con la asociada a la región (el promedio de las direcciones de cada uno de los píxeles). Sin embargo, se elige el centro del segmento como el centro de masa de la región y su dirección como el eje de inercia principal de la misma; la magnitud del gradiente asociado a cada píxel hace las veces de masa. La idea detrás de este método es que los píxeles con un gradiente mayor en módulo, se corresponden mejor con la percepción de un borde. La anchura y la longitud del segmento son elegidos de manera de cubir el $99\%$ de la masa de la región.

\section{Validación de segmentos}
La validación de los segmentos previamente detectados se plantea como un método de test de hipótesis. Se utiliza un modelo \textit{a contrario}: dada una imagen de ruido blanco y Gaussiano, se sabe que cualquier tipo de estructura detectada sobre la misma será casual. En rigor, se sabe que para cualquier imagen de este tipo, su \textit{level-line orientation field} toma, para cada píxel, valores independientes y uniformemente distribuídos entre $[0,2\pi]$. Dado entonces un segmento en la imagen analizada, se estudia la probabilidad de que dicha detección se dé en la imagen de ruido, y si \'esta es lo suficientemente baja, el segmento se considerará válido, de lo contrario se considerará que se esta bajo la hipótesis $H_0$: un conjunto aleatorio de píxeles que casualmente se alinearon de manera de detectar un segmento.\\
Para estudiar la probabilidad de ocurrencia de una cierta detección en la imagen de ruido, se deben tomar en cuenta todos los rectángulos potenciales dentro de la misma. Dada una imagen $N\times N$, habrán $N^4$ orientaciones posibles para los segmentos, $N^2$ puntos de inicio y $N^2$ puntos de fin. Si se consideran $N$ posibles valores para la anchura de los rectángulos, se obtienen $N^5$ posibles segmentos. Por su parte, dado cierto rectángulo $r$, detectado en la imagen $x$, se denota $k(r,x)$ a la cantidad de píxeles alineados dentro del mismo. Se define además un valor llamado \textit{Number of False Alarms} (NFA) que está fuertemente relacionado con la probabilidad de detectar al rectángulo en cuestión en la imagen de ruido $X$:
\[
NFA(r,x) = N^5. P_{H_0}[k(r,X) \geq k(r,x) ]
\]
véase que el valor se logra multiplicando la probabilidad de que un segmento de la imagen de ruido, de tama\~no igual a $r$, tenga un número mayor o igual de píxeles alineados que éste, por la cantidad potencial de segmentos $N^5$. Cuanto menor sea el número NFA, más significativo será el segmento detectado r; pues tendrá una probabilidad de aparición menor en una imagen sin estructuras. De esta manera, se descartará $H_0$; o lo que es lo mismo, se aceptará el segmento detectado como válido, si y sólo si:
\[
NFA(r) \leq \epsilon
\] 
donde empiricamente $\epsilon=1$ para todos los casos.\\
Si se toma en cuenta que cada píxel de la imagen ruidosa toma un valor independiente de los demás, se concluye que también lo harán el gradiente y el \textit{level-line orientation field}. De esta menera, definido sobre ésta un segmento con cierta orientación, la probabilidad de que uno de sus píxeles cuente con la misma orientación, a menos de la ya mencionada tolerancia $\tau$; será:
\[
p = \frac{\tau}{\pi}
\]
además, se puede modelar la probabilidad de que cierto rectángulo en la imagen ruidosa, con cualquier orientación, formado por $n(r)$ píxeles, cuente con al menos $k(r)$ de ellos alineados, como una distribución binomial:
\[
P_{H_0}[k(r,X) \geq k(r,x) ] = B(n(r), k(r),p).
\]
Finalmente, el valor \textit{Number of False Alarms} será calculado para cada segmento detectado en la imgen analizada de la sigiuente manera:
\[
NFA(r,x) = N^5. B(n(r), k(r),p);
\]
si dicho valor es menor o igual a $\epsilon=1$, el segmento se tomará como válido; de lo contrario de dacartará.

\section{Refinamiento de los candidatos}
Por lo que se vi\'o hasta el momento, la mejor aproximaci\'on rectangular a una \textit{line-support region} es la que obtenga un valor NFA menor. Para los segmentos que no son validados, se prueban algunas variaciones a la aproximaci\'on original con el objetivo de disminuír su valor NFA y así entonces validarlos. Esta claro que este paso no es significativo para segmentos largos y bien definidos, ya que estos ser\'an validados en la primera inspecci\'on; sin embargo, ayuda a detectar segmentos más peque\~nos y algo ruidosos. \\
Lo que se hace es probar distintos valores para la anchura del segmento y para sus posiciones laterales, ya que estas son los par\'ametros peor estimados en la aproximaci\'on rectangular, pero tienen un efecto muy grande a la hora de validar los segmentos. Es que un error de un p\'ixel en el ancho de un segmento, agrega una gran cantidad de p\'ixeles no alineados a este, y esto se ve reflejado en un valor mayor de NFA y puede llevar a una no detecci\'on.\\
Otro m\'etodo para el refinamiento de los candidatos es la disminución de la tolerancia $\tau$. Si los puntos dentro del rectángulo efectivamente corresponden a un segmento, aunque la tolerancia disminuya, se computará prácticamente misma cantidad de segmentos alineados, y con una probabilidad menor de ocurrencia ($\frac{\tau}{\pi}$), el valor NFA obtenido será menor. Los nuevos valores testeados de tolerancia son: $\frac{\tau}{2}$, $\frac{\tau}{4}$,$\frac{\tau}{8}$,$\frac{\tau}{16}$ y $\frac{\tau}{32}$. El valor NFA asociado al segmento será el menor de todos los calculados.\\  
\section{Optimización del algoritmo para tiempo real}

\section{Resutados}