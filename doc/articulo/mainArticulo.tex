\documentclass[journal]{IEEEtran}

%IDIOMA
\usepackage[spanish]{babel}
\usepackage[latin1]{inputenc}  % Ambos para solucin de asuntos de idioma
\usepackage[T1]{fontenc}

%MATH
\usepackage{amsmath,amssymb,mathrsfs,mathptmx}  % Matemticas varias
\usepackage{hyperref} % Para escribir URLs
\usepackage[]{algorithm2e}
\usepackage{verbatim}

%IMAGES
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{float}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage[usenames,dvipsnames]{color}
\graphicspath{{../latex/}}
\DeclareGraphicsExtensions{.png,.jpg,.pdf,.mps,.gif,.bmp, .eps}
\usepackage{caption}

%VARIOS
\usepackage{multirow}
\usepackage{multicol}
\usepackage{tabulary}
\usepackage[table]{xcolor}
\usepackage{color}
\usepackage{listings}
\usepackage{tikz}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{2}

\begin{document}

\title{enCuadro\\
\huge Recorrido interactivo en museos con realidad aumentada sobre dispositivos móviles}

\author{Juan Braun, Martín Etchart, Pablo Flores y Mauricio González}% <-this % stops a space

% make the title area
\maketitle


\begin{abstract}
%\boldmath
The abstract goes here.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
IEEEtran, journal, \LaTeX, paper, template.
\end{IEEEkeywords}

%\include{alcance}

\section{Modelo de cámara \textit{pin-hole}}
\label{sec:Calibracion de camara}

Este modelo consiste en un centro óptico O, en donde convergen todos los rayos de la proyección y un plano imagen en el cual la imagen es proyectada. Se define \textit{distancia focal} ($f$) como la distancia entre el centro óptico O y la intersección del eje óptico con el plano imagen (punto C). Ver Figura \ref{fig:CalibracionCamara}.  

\begin{figure}[h!]
\centering
\includegraphics[scale=0.4]{figs_camaraypose/CalibracionCamara.eps}
\caption{Modelo de cámara pin-hole.}
\label{fig:CalibracionCamara}
\end{figure}

Se llama proceso de proyección al proceso en el que se asocia al punto \textbf{M} del mundo, un punto \textbf{m} en la imagen. Para modelar el mismo es necesario referirse a varias transformaciones y varios ejes de coordenadas.
\begin{itemize}
\item \textit{Coordenadas del mundo}: son las coordenadas que describen la posición 3D del punto \textbf{M} respecto de los ejes del mundo $(u,v,w)$. La elección de los ejes del mundo es arbitraria.
\item \textit{Coordenadas de la cámara}: son las coordenadas que describen la posición del punto \textbf{M} respecto de los ejes de la cámara $(X,Y,Z)$. $i$, $j$ y $k$ son los versores de este eje de coordenadas.
\item \textit{Coordenadas de la imagen}: son las coordenadas que describen la posición del punto 2D, \textbf{m} respecto del centro del plano imagen, C. Los ejes de este sistema de coordenadas son $(x,y)$.
\item \textit{Coordenadas normalizadas de la imagen}: son las coordenadas que describen la posición del punto 2D, \textbf{m}, respecto del eje de coordenadas $(x',y')$ situado en la esquina superior izquierda del plano imagen.
\end{itemize}
La transformación que lleva al punto \textbf{M}, expresado respecto de los ejes del mundo, al punto \textbf{m}, expresado respecto del sistema de coordenadas normalizadas de la imagen, se puede ver como la composición de dos transformaciones menores. La primera, es la que realiza la proyección que transforma a un punto definido respecto del sistema de coordenadas de la cámara $(X, Y, Z)$ en otro punto sobre el plano imagen expresado respecto del sistema de coordenadas normalizadas de la imagen $(x',y')$. Véase que una vez calculada esta transformación, es una constante característica de cada cámara. Al conjunto de valores que definen esta transformación, se le llama ``{parámetros intrínsecos'' de la cámara. La segunda, es la transformación que lleva de expresar un punto respecto de los ejes del mundo $(u,v,w)$, a ser expresado según los ejes de la cámara $(X ,Y, Z)$. Esta última transformación varía conforme se mueve la cámara (respecto de los ejes del mundo) y el conjunto de valores que la definen es denominado ``parámetros extrínsecos'' de la cámara. Del cálculo de estos parámetros es que se obtiene la estimación de la pose de la cámara.
De lo anterior se concluye rápidamente que si se le llama $H$ a la matriz proyección total, tal que:
\[
m = H.M,
\]
entonces:
\[
H = I.E
\]
donde $I$ corresponde a la matriz proyección asociada a los parámetros intrínsecos y $E$ corresponde a la matriz asociada a los parámetros extrínsecos. 

\begin{itemize}
\item \textbf{Parámetros extrínsecos:} pose de la cámara.
\begin{itemize}
\item \underline{Traslación:} ubicación del centro óptico de la cámara respecto de los ejes del mundo.
\item \underline{Rotación:} rotación del sistema de coordenadas de la cámara $(X ,Y, Z)$, respecto de los ejes del mundo.
\end{itemize}
\item \textbf{Parámetros intrínsecos:} parámetros propios de la cámara. Dependen de su geometría interna y de su óptica.
\begin{itemize}
\item \underline{Punto principal (C = [$x'_C,y'_C$]):} es el punto intersección entre el eje óptico y el plano imagen. Las coordenadas de este punto vienen dadas en píxeles y son expresadas respecto del sistema normalizado de la imagen.
\item \underline{Factores de conversión píxel-milímetros ($d_x,d_y$):} indican el número de píxeles por milímetro que utiliza la cámara en las direcciones $x$ e $y$ respectivamente.
\item \underline{Distancia focal (f):} distancia entre el centro óptico (\textbf{O}) y el punto principal (\textbf{C}). Su unidad es el milímetro.
\item \underline{Factor de proporción (s):} indica la proporción entre las dimensiones horizontal y vertical de un píxel.   
\end{itemize}
\end{itemize}


\subsection{Matriz de proyección}
\label{sec:Matriz de proyección}

En la sección anterior se vio que es posible hallar una ``matriz de proyección'' H que dependa tanto de los parámetros intrínsecos de la cámara como de sus parámetros extrínsecos:
\[
m = H.M
\] 
donde \textbf{M} y \textbf{m} son los puntos ya definidos y vienen expresados en ``coordenadas homogéneas''. Por más información acerca de este tipo de coordenadas ver \cite{Hartley2004}.\\
Para determinar la forma de la matriz de proyección se estudia cómo se relacionan las coordenadas de \textbf{M} con las coordenadas de \textbf{m}; para hallar esta relación se debe analizar cada transformación, entre los sistemas de coordenadas mencionados con anterioridad, por separado.\\
\begin{itemize}
\item \textbf{Proyección 3D - 2D:} de las coordenadas homogéneas del punto \textbf{M} expresadas en el sistema de coordenadas de la cámara $(X_0,Y_0,Z_0,T_0)$, a las coordenadas homogéneas del punto \textbf{m} expresadas en el sistema de coordenadas de la imagen $(x_0,y_0,s_0)$:\\
Se desprende de la Figura \ref{fig:CalibracionCamara} y algo de trigonometría la siguiente relación entre las coordenadas en cuestión y la distancia focal (f):
\[
\frac{f}{Z_0} = \frac{x_0}{X_0} = \frac{y_0}{Y_0}
\]
A partir de la relación anterior:
\[
\left( \begin{array}{c}
x_0 \\
y_0
\end{array} \right)
=
\frac{f}{Z_0} 
\left( \begin{array}{c}
X_0 \\ 
Y_0
\end{array} \right)
\]
Expresado en forma matricial, en coordenadas homogéneas:
\[
\left( \begin{array}{c}
x_0 \\
y_0 \\
s_0
\end{array} \right)
= 
\left( \begin{array}{cccc}
f & 0 & 0 & 0 \\ 
0 & f & 0 & 0 \\
0 & 0 & 1 & 0
\end{array} \right)
\left( \begin{array}{c}
X_0 \\ 
Y_0 \\
Z_0 \\
1
\end{array} \right)
\]
\item \textbf{Transformación imagen - imagen:} de las coordenadas homogéneas del punto \textbf{m} expresadas respecto del sistema de coordenadas de la imagen $(x_0,y_0,s_0)$, a las coordenadas homogéneas de él mismo pero expresadas respecto del sistema de coordenadas normalizadas de la imagen $(x'_0,y'_0,s'_0)$:

Se les suma, a las coordenadas de \textbf{m} respecto del sistema de la imagen, la posición del punto C respecto del sistema normalizado de la imagen $(x'_C,y'_C)$. Las coordenadas de \textbf{m} dejan de ser expresadas en milímetros para ser expresadas en píxeles. Aparecen los factores de conversión $d_x$ y $d_y$:
\[
\begin{array}{c}
x'_0 = d_x.x_0 + x'_C \\
y'_0 = d_y.y_0 + y'_C
\end{array}
\]
Se obtiene entonces la siguiente relación matricial, en coordenadas homogéneas:
\[
\left( \begin{array}{c}
x'_0 \\
y'_0 \\
s'_0
\end{array} \right)
= 
\left( \begin{array}{ccc}
d_x & 0 & x'_C \\ 
0 & d_y & y'_C \\
0 & 0 & 1
\end{array} \right)
\left( \begin{array}{c}
x_0 \\ 
y_0 \\
1
\end{array} \right)
\]
\item \textbf{Matriz de parámetros intrínsecos $(I)$:} de las coordenadas homogéneas del punto \textbf{M} expresadas en el sistema de coordenadas de la cámara $(X_0,Y_0,Z_0,1)$, a las coordenadas homogéneas del punto \textbf{m} expresadas respecto del sistema de coordenadas normalizadas de la imagen $(x'_0,y'_0,s'_0)$:\\
Se obtiene combinando las dos últimas transformaciones. Nótese que como ya se aclaró, depende únicamente de parámetros propios de la construcción de la cámara:
\[
I = 
\left( \begin{array}{cccc}
d_x.f & 0 & x'_C & 0\\ 
0 & d_y.f & y'_C & 0\\
0 & 0 & 1 & 0
\end{array} \right)
\]

\item \textbf{Matriz de parámetros extrínsecos $(E)$:}  de las coordenadas homogéneas del punto \textbf{M} expresadas respecto del sistema de coordenadas del mundo $(U_0, V_0, W_0, P_0)$, a las coordenadas homogéneas de él mismo pero expresadas respecto del sistema de coordenadas de la cámara $(X_0,Y_0,Z_0,T_0)$:\\
Se obtiene de estimar la pose de la cámara respecto de los ejes del mundo y es la combinación de, primero una rotación $R_{3x3}$, y luego una traslación $T_{3x1}$. Se obtiene entonces la siguiente representación matricial:\\
\[
\left( \begin{array}{c}
X_0 \\
Y_0 \\
Z_0 \\
T_0
\end{array} \right)
= 
\left( \begin{array}{cc}
R & T \\ 
0 & 1
\end{array} \right)
\left( \begin{array}{c}
U_0 \\ 
V_0 \\
W_0 \\
P_0
\end{array} \right)
\]
donde la matriz de parámetros extrínsecos desarrollada toma la forma:
\[
E =
\left( \begin{array}{cccc}
i_u & i_v & i_w & t_{x} \\ 
j_u & j_v & j_w & t_{y}\\
k_u & k_v & k_w & t_{z} \\
0 & 0 & 0 & 1
\end{array} \right)
\]  
\item \textbf{Matriz de proyección $(H)$:}  de las coordenadas homogéneas del punto \textbf{M} expresadas respecto del sistema de coordenadas del mundo $(U_0, V_0, W_0, P_0)$, a las coordenadas homogéneas del punto \textbf{m} expresadas respecto del sistema de coordenadas normalizadas de la imagen $(x'_0,y'_0,s'_0)$:\\
Es la proyección total y se obtiene combinando las dos transformaciones anteriores:
\end{itemize}
\section{Marcadores}
La inclusión de \emph{marcadores} en la escena ayuda al problema de extracción de características y por lo tanto al problema de estimación de pose. Estos por construcción son elementos que presentan una detección estable en la imagen para el tipo de característica que se desea extraer así como medidas fácilmente utilizables para la estimación de la pose.

El marcador utilizado está basado en la estructura de detección incluida en los códigos \emph{QR} y se muestra en la Figura \ref{fig:Marker}. Éste consiste en tres grupos idénticos de tres cuadrados concéntricos superpuestos en ``capas''. La primer capa contiene el cuadrado negro de mayor tamaño, en la segunda capa se ubica el cuadrado mediano en color blanco y en la última capa un cuadrado negro pequeño. De esta forma se logra un fuerte contraste en los lados de cada uno de los cuadrados facilitando la detección de bordes o líneas. A diferencia de los códigos \emph{QR} la disposición espacial de los grupos de cuadrados es distinta para evitar ambigüedades en la identificación de los mismos entre sí. 
\begin{figure}[h!]
\centering
\includegraphics[scale=0.15]{figs_detection/Marker.eps}
\caption{Marcador propuesto basado en la estructura de detección de códigos QR.}
\label{fig:Marker}
\end{figure}

\subsection{Estructura del marcador}
\label{sec:detection_estructuras}
A continuación se presentan algunas definiciones de las estructuras básicas que componen el marcador propuesto. Estas son de utilidad para el diseño y forman un flujo natural y escalable para el desarrollo del algoritmo de determinación de correspondencias.

Los elementos más básicos en la estructura son los \emph{segmentos} los cuales consisten en un par de puntos en la imagen, $\mathbf{p} = (p_x,p_y)$ y $\mathbf{q} = (q_x,q_y)$. Estos \emph{segmentos} forman lo que son los lados del \emph{cuadrilátero}, el próximo elemento estructural del marcador.

Un \emph{cuadrilátero} o \emph{quadrilateral} en inglés, al que se le denomina $Ql$, está determinado por cuatro segmentos conexos y distintos entre sí. El cuadrilátero tiene dos propiedades notables; el \emph{centro} definido como el punto medio entre sus cuatro vértices y el \emph{perímetro} definido como la suma de el largo de sus cuatro lados.

A un \emph{conjunto de cuadriláteros} o \emph{quadrilateral set} se le denomina $QlSet$ y se construye a partir de $M$ cuadriláteros, con $M>1$. Los cuadriláteros comparten un mismo centro pero se diferencian en un factor de escala. A partir de dichos cuadriláteros se construye un lista ordenada $(Ql[0],Ql[1],\dots,Ql[M-1])$ en donde el orden viene dado por el valor de perímetro de cada $Ql$. Se define el \emph{centro del grupo de cuadriláteros}, $\mathbf{c}_i$, como el promedio de los centros de cada $Ql$ de la lista ordenada.

Finalmente el \emph{marcador QR} está constituido por $N$ conjuntos de cuadriláteros dispuestos en una geometría particular. Esta geometría permite la determinación de un sistema de coordenadas; un origen y dos ejes a utilizar. Se tiene una lista ordenada  $(QlSet[0],QlSet[1],\dots,QlSet[N-1])$ en donde el orden se puede determinar mediante la disposición espacial de los mismos o a partir de hipótesis razonables.

\subsection{Diseño}
En base a las estructuras previamente definidas es que se describe el diseño del marcador. Como ya se explicó se toma un marcador tipo QR basado en cuadriláteros y más específicamente en tres conjuntos de tres cuadrados dispuestos en como se muestra en la Figura \ref{fig:Marker}.

Los tres cuadriláteros correspondientes a un mismo conjunto de cuadriláteros tienen idéntica alineación e idéntico centro. Los diferencia un factor de escala, esto es, $Ql[0]$ tiene lado $l$ mientras que $Ql[1]$ y $Ql[2]$ tienen lado $2l$ y $3l$ respectivamente. Esto se puede ver en la Figura \ref{fig:QlSetDetail}. Adicionalmente se define un sistema de coordenadas con centro en el centro del $QlSet$ y ejes definidos como $\textbf{x}$ horizontal a la derecha e $\textbf{y}$ vertical hacia abajo.  Definido el sistema de coordenadas se puede fijar un orden a los vértices $v_{j_{1}}$ de cada cuadrilátero $Ql[j]$ como,
\begin{align*}
v_{j_{0}} = (a/2,a/2) && v_{j_{2}} = (-a/2,-a/2)  \\
v_{j_{1}} = (a/2,-a/2)&& v_{j_{3}} = (-a/2,a/2)
\end{align*}
con $a=(j+1)\times l$. El orden aquí explicado se puede ver también junto con el sistema de coordenadas en la Figura \ref{fig:MarkerDetail}.
\begin{figure}[h!]
\centering
\includegraphics[scale=0.15]{figs_detection/QlSetDetail.eps}
\caption{Detalle de un $QlSet$. A la izquierda se muestra el resultado de la detección de un $QlSet$ y el orden interno de sus cuadriláteros y a la derecha el orden de los vértices respecto al sistema de coordenadas local.}
\label{fig:QlSetDetail}
\end{figure}

Un detalle del marcador completo se muestra en la Figura \ref{fig:MarkerDetail} en donde se define el conjunto $i$ de cuadriláteros concéntricos como el $QlSet[i]$ y se definen los respectivos centros de cada uno de ellos como $\mathbf{c}_i$. El sistema de coordenadas del marcador QR tiene centro en el centro del $QlSet[0]$ y ejes de coordenadas idénticos al definido para cada $Ql$. Se tiene además que los ejes de coordenadas pueden ser obtenidos mediante los vectores normalizados,
\begin{equation}
\begin{split}
\mathbf{x}  = \frac{\mathbf{c}_1 - \mathbf{c}_0}{||\mathbf{c}_1-\mathbf{c}_0||} & \quad
\mathbf{y}  = \frac{\mathbf{c}_2 - \mathbf{c}_0}{||\mathbf{c}_2-\mathbf{c}_0||}
\end{split} 
\label{ec:detection_ejes}
\end{equation}

La disposición de los $QlSet$ es tal que la distancia indicada $d_{01}$ definida como la norma del vector entre los centros $\mathbf{c}_1$ y $\mathbf{c}_0$ es significativamente mayor que la distancia $d_{02}$ definida como la norma del vector entre los centros $\mathbf{c}_2$ y $\mathbf{c}_1$. Esto es, $d_{01}\gg d_{02}$. Este criterio facilita la identificación de los $QlSet$ entre sí basados únicamente en la posición de sus centros y es explicado en la sección de determinación de correspondencias.
\begin{figure}[h!]
\centering
\includegraphics[scale=0.13]{figs_detection/MarkerDetail.eps}
\caption{Detalle del marcador propuesto formando un sistema de coordenadas.}
\label{fig:MarkerDetail}
\end{figure}

\subsection{Diseño utilizado}
\textbf{Diseño de Test}: Durante el desarrollo e implementación de los algoritmos de detección e identificación de los vértices del marcador se trabajó con determinados parámetros de diseño de dimensiones apropiadas para posibilitar el traslado y las pruebas domésticas. 
\begin{itemize}
 \item $l = 30 mm$
 \item $d_{01} = 190 mm$
 \item $d_{02} = 100 mm$
\end{itemize}

\section{Detección}
La etapa de detección del marcador se puede separar en tres grandes bloques:
\begin{itemize}
 \item Detección de segmentos de línea.
 \item Filtrado y agrupamiento de segmentos.
 \item Determinación de correspondencias.
\end{itemize}
En esta sección se muestran algunos resultados para la detección de segmentos de línea por LSD y se centra en profundidad en los algoritmos desarrollados durante el proyecto para el filtrado de segmentos y determinación de correspondencias.

\subsection{Detección de segmentos de línea}
La detección de segmentos de línea se realiza mediante el uso del algoritmo LSD. En forma resumida, dicho algoritmo toma como entrada una imagen en escala de grises de tamaño $W\times H$ y devuelve una lista de segmentos en forma de pares de puntos de origen y destino. 

\subsection{Filtrado y agrupamiento de segmentos}
El filtrado y agrupamiento de segmentos consiste en la búsqueda de conjuntos de cuatro segmentos conexos en la lista de segmentos de línea detectados por LSD. Los conjuntos de segmentos conexos encontrados se devuelven en una lista en el mismo formato a la de LSD pero agrupados de a cuatro. A continuación se realiza una breve descripción del algoritmo de filtrado de segmentos implementado.

Se parte de una lista de $m$ segmentos de línea,
\begin{equation}
 \mathbf{L} = \begin{pmatrix}
               \mathbf{s}_0 & \mathbf{s}_1 & \dots & \mathbf{s}_{m-1} 
              \end{pmatrix}^t
\end{equation}
y se recorre en $i$ en busca de segmentos vecinos. La estrategia utilizada consiste en buscar, para el $i$-ésimo segmento $\mathbf{s}_i$, dos segmentos vecinos. En una primera etapa $\mathbf{s}_j$ y en una segunda etapa $\mathbf{s}_k$, de forma que se forme una ``U'' como se muestra en la Figura \ref{fig:SegmentosRectas}. La tercer etapa de búsqueda consiste en completar ese conjunto con un cuarto segmento $\mathbf{s}_l$ que cierre la ``U''.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.5]{figs_detection/SegmentosRectas.eps}
\caption{Conjunto de cuadriláteros conexos. A la izquierda la primera y segunda etapa del filtrado completadas para el segmento $\mathbf{s}_i$ en donde se busca una ``U''. A la derecha la última etapa en donde se cierra la ``U'' con el segmento $\mathbf{s}_l$.}
\label{fig:SegmentosRectas}
\end{figure}

Una vez encontrado el conjunto de cuatro segmentos conexos estos se marcan como utilizados, se guardan en una lista de salida y se continúa con el segmento $i+1$ hasta recorrer los $m$ segmentos de la lista de entrada. De esta forma se obtiene una lista de salida $\mathbf{S}$ de $n$ segmentos en donde $n$ es por construcción múltiplo de cuatro.

En la Figura \ref{fig:resultado_lsdfilt} se muestran lo resultados obtenidos para el algoritmo tomando como entrada la lista de segmentos de LSD. Se puede ver que los lados de los cuadrados del marcador son detectados correctamente pero también hay otras detecciones presentes. 
\begin{figure}[h!]
  \centering
  \subfigure[Entrada: segmentos de línea detectados por LSD]{
    \includegraphics[scale=0.25]{figs_detection/lsd.png}}
  \subfigure[Salida: segmentos de línea filtrados y agrupados]{
    \includegraphics[scale=0.25]{figs_detection/lsdfilt.png}}
  \caption{Resultados del algoritmo de filtrado y agrupamiento de segmentos de línea.}
  \label{fig:resultado_lsdfilt}
\end{figure}

El algoritmo descrito es simple y provee resultados aceptables en general pero es propenso a tanto a detectar \emph{falsos positivos} como al \emph{sobre-filtrado} algunos conjuntos. 

\subsection{Determinación de correspondencias}
\label{sec:detection_correspondencias}
Se detalla a continuación el algoritmo de determinación de correspondencias a partir de grupos de cuatro segmentos de línea conexos. 

Se toma como entrada la lista de segmentos filtrados y agrupados
\begin{equation}
\mathbf{S} = \begin{pmatrix}
			 \mathbf{s}_0 & \mathbf{s}_1 & \dots & \mathbf{s}_{i} & \mathbf{s}_{i+1} & \mathbf{s}_{i+2} & \mathbf{s}_{i+3} & \dots & \mathbf{s}_{n-1}
			 \end{pmatrix}^t
\end{equation}
en donde cada segmento se compone de un punto inicial $\mathbf{p}_{i}$ y un punto final $\mathbf{q}_{i}$, $\mathbf{s}_{i} = (\mathbf{p}_{i},\mathbf{q}_{i})$, con $n$ múltiplo de cuatro. Si $i$ también lo es, entonces el sub-conjunto, 
$\mathbf{S}_i = \begin{pmatrix}
				\mathbf{s}_{i} & \mathbf{s}_{i+1} & \mathbf{s}_{i+2} & \mathbf{s}_{i+3}
				\end{pmatrix}^t$, corresponde a un conjunto de cuatro segmentos del línea conexos.

Para cada sub-conjunto $\mathbf{S}_i$ se intersectan entre sí los segmentos obteniendo una lista de cuatro vértices,
$\mathbf{V}_i =  \begin{pmatrix}
		 \mathbf{v}_{i} & \mathbf{v}_{i+1} & \mathbf{v}_{i+2} & \mathbf{v}_{i+3} 
		 \end{pmatrix}^t$. 
Se obtienen dos posibles configuraciones que se muestran en la Figura \ref{fig:Vertices}, una de ellas tiene sentido horario y la otra antihorario partiendo de ${v}_i$.
\begin{figure}[h!]
\centering
\includegraphics[scale=0.5]{figs_detection/Vertices.eps}
\caption{Posibles configuraciones de vértices posterior a la intersección de conjuntos de segmentos pertenecientes a un cuadrilátero.}
\label{fig:Vertices}
\end{figure}

Posterior a la intersección se realiza un chequeo sobre el valor de las coordenadas de los vértices. Si alguno de ellos se encuentra fuera de los límites de la imagen, el conjunto de cuatro segmentos es marcado como inválido. Este chequeo resulta en el filtrado de ``falsos cuadriláteros'' corrigiendo un defecto del filtrado de segmentos, como por ejemplo un grupo de segmentos paralelos cercanos como ya se explicó. 

Para cada uno de los conjuntos de vértices se construye con ellos un elemento cuadrilátero que se almacena en una lista de cuadriláteros
\begin{eqnarray*}
 QlList =  \begin{pmatrix}
            Ql[0] & Ql[1] & \dots & Ql[i] & \dots & Ql[\frac{n}{4}]
           \end{pmatrix}^t
\end{eqnarray*}
% en sentido amplio, de dos segmentos contiguos, $s_i\cap s_{i+1}$ dadas las recta $r_1$ que pasa por los puntos $\mathbf{p}_1$, $\mathbf{q}_1$ del segmento $s_1$ y la recta $r_2$ que pasa por los puntos $\mathbf{p}_2$, $\mathbf{q}_2$ del segmento $s_2$, se determina el vértice correspondiente como la intersección $r_1 \cap r_2$. \\
% 
% y se intersectan en grupos de cuatro obteniendo cuatro vértices por cada grupo. Para cada grupo de vértices $v_k$ se construye un elemento cuadrilátero $\text{Ql}[k]$ que se almacena en una lista de cuadriláteros. 

A partir de esa lista de cuadriláteros, se buscan grupos de tres cuadriláteros $QlSet$ que ``compartan'' un mismo centro. Para esto se recorre ordenadamente la lista en $i$ buscando para cada cuadrilátero dos cuadriláteros $j$ y $k$ que cumplan que la distancia entre sus centros  y el del $i$-ésimo cuadrilátero sea menor a cierto umbral $c_{th}$,
\begin{equation}
\begin{split}
 d_{ij} = ||\mathbf{c}_i - \mathbf{c}_j||<c_{th}, & \quad  d_{ik} = ||\mathbf{c}_i - \mathbf{c}_k||<c_{th}.
\end{split}
\end{equation}
Estos cuadriláteros se marcan en la lista como utilizados con ellos se forma el $l$-ésimo $QlSet$ ordenándolos según su perímetro, de menor a mayor como  
$$QlSet[l] = \begin{pmatrix} Ql[0] & Ql[1] & Ql[2] \end{pmatrix}$$
con $l = (0,1,2)$. Esta búsqueda se realiza hasta encontrar un total de tres $QlSet$ completos de forma de obtener un marcador completo, esto es, detectando todos los cuadriláteros que lo componen. 

Una vez obtenida la lista de tres $QlSet$, 
$$QlSetList = \begin{pmatrix} QlSet[0] & QlSet[1] & QlSet[2] \end{pmatrix}$$
ésta se ordena de forma que su disposición espacial se corresponda con la del marcador QR. Para esto se calculan las distancias entre los centros de cada $QlSet$ y se toma el índice $i$ como el índice que produce el vector de menor distancia, $\mathbf{u}_i = \mathbf{c}_{i+1} -\mathbf{c}_i$. En este punto es importante que la condición de distancia entre los centros de los $QlSet$ se cumpla, $d_{10} \gg d_{20}$, para una simple identificación.

Una vez seleccionado el vector $\mathbf{u}_i$, se tienen obtiene el juego de vectores $(\mathbf{u}_i,\mathbf{u}_{i+1},\mathbf{u}_{i+2})$ como se muestra en la Figura \ref{fig:Centros}.
\begin{figure}[h!]
\centering
\includegraphics[scale=0.28]{figs_detection/Centros.eps}
\caption{Vértices de cada $Ql$ ordenados respecto al signo de sus proyecciones contra el sistema de coordenadas local a cada $QlSet$.}
\label{fig:Centros}
\end{figure}

Existen solo dos posibles configuraciones para estos vectores por lo que se utiliza este conocimiento para ordenar los $QlSet$ de la lista realizando el producto vectorial $\hat{\mathbf{u}_i} \times \hat{\mathbf{u}_{i+1}}$. 

Se construye un marcador QR que contiene la lista de tres $QlSet$ ordenados según lo indicado permitiendo la definición de un centro de coordenadas como el centro $\mathbf{c}_0$ del $QlSet[0]$ y ejes de coordenadas definidos en la Ecuación \ref{ec:detection_ejes}. 
De esta forma, recorriendo ordenadamente los elementos del marcador, se ordenan los vértices de cada $Ql$ del marcador.

Por último, a partir del marcador ordenado, se extrae una lista de vértices que se corresponde con la lista de vértices del marcador en coordenadas del mundo. Se determinan las correspondencias $\mathbf{M}_i\leftrightarrow \mathbf{m}_i$ necesarias para la estimación de pose. El algoritmo de determinación de correspondencias funciona correctamente por lo que los ``falsos'' cuadriláteros que sobreviven al filtrado de segmentos no son un problema.



\section{POSIT}
A continuación se explica el algoritmo utilizado para el cálculo de la pose a partir de una imagen capturada por la cámara. Como lo dice el nombre del algoritmo se utiliza una técnica llamada \textit{POS} (\textit{P}ose from \textit{O}rtography and \textit{S}caling), esta técnica consiste en aproximar la pose de la cámara a partir de la proyección \textit{SOP}(\textit{S}caled \textit{O}rtographic \textit{Projection}). 

\subsection{Notación}
En la Figura \ref{fig: posit_1} se puede ver nuevamente el modelo de cámara pinhole. $O$ es el centro óptico y $G$ es el plano imagen ubicado  a una distancia focal $f$ de $O$. $x$ e $y$ son los ejes que apuntan en las direcciones de las filas y las columnas del sensor de la cámara respectivamente. $z$ es el eje que esta sobre el eje óptico de la cámara y apunta en sentido saliente. Los versores para estos ejes son \textbf{i}, \textbf{j} y \textbf{k} respectivamente.

Se considera ahora un objeto con puntos característicos $M_0$, $M_1$, ...., $M_i$, ...., $M_n$, cuyo eje de coordenadas está centrado en $M_0$ y está compuesto por los versores ($M_0u$, $M_0v$, $M_0w$ ). Como los ejes del mundo son arbitrarios se puede asumir sin pérdida de generalidad que los ejes del objeto coinciden con los ejes del mundo. La geometría del objeto se asume conocida, por ejemplo ($U_i$, $V_i$, $W_i$) son las coordenadas del punto $M_i$ en el marco de referencia del objeto.
Los puntos correspondientes a los puntos del objeto $M_i$ en la imagen son conocidos y se identifican como $m_i$, ($x_i$, $y_i$) son las coordenadas de este punto en la imagen\footnote{En realidad los puntos $m_i$ no están dados, vienen de la etapa anterior de detección.}. Las coordenadas de los puntos $M_i$ en el eje de coordenadas de la cámara, identificadas como ($X_i$, $Y_i$, $Z_i$), son desconocidas ya que no se conoce la pose del objeto respecto a la cámara.

\begin{figure}[h!]
\centering
\includegraphics[scale=0.3]{figs_posit/posit_1.eps}
\caption{Proyección en perspectiva ($m_i$) y SOP ($p_i$) para un punto del modelo 3D $M_i$ y un punto de referencia del modelo $M_O$. Tomado de: \cite{DeMenthon95}.}
\label{fig: posit_1}
\end{figure}

Se busca computar la matriz de rotación y el vector de traslación del objeto respecto a la cámara. 


\subsection{SOP: \textit{S}caled \textit{O}rtographic \textit{P}rojection}
La proyección ortogonal escalada(SOP) es una aproximación a la proyección perspectiva. En esta aproximación se supone que las profundidades $Z_i$ de diferentes puntos $M_i$ en el eje de coordenadas de la cámara no difieren mucho entre sí, y por lo tanto se asume que todos los puntos $M_i$ tienen la misma profundidad que el punto $M_0$. Esta suposición es razonable cuando la relación distancia cámara objeto - profundidad del objeto es grande.

Para un punto $M_i$ la proyección perspectiva sobre el plano imagen está dada por:
\begin{align*}
x_i &= f X_i/Z_i,  & y_i& = fY_i/Z_i,
\end{align*}
mientras que la proyección SOP está dada por: 
\begin{align*}
x^{'}_i &= f X_i/Z_0, & y^{'}_i& = fY_i/Z_0. 
\end{align*}
Al término $s=f/Z_0$ se lo conoce como el factor de escala de la SOP.

En la Figura \ref{fig: posit_1} se puede ver como se construye la SOP. Primero se realiza la proyección ortogonal de todos los puntos $M_i$ sobre $K$, el plano paralelo al plano imagen que pasa por el punto $M_0$. Las proyecciones de los puntos $M_i$ sobre $K$ se llaman $P_i$. El segundo paso consiste en hacer la proyección perspectiva de los puntos $P_i$ sobre el plano imagen $G$ para obtener finalmente los puntos $p_i$. 

\subsection{Ecuaciones para calcular la proyección perspectiva}

La pose queda determinada si se conocen los vectores \textbf{i}, \textbf{j} y la coordenada \textbf{$Z_0$} del vector de traslación. La relación entre las coordenadas de los puntos $M_i$  en el sistema de coordenadas del objeto y el sistema de coordenadas de la cámara es
\begin{equation}\label{posit_eq1}
 \left(\begin{array}{ccc}
 X_i \\
 Y_i \\
 Z_i \\
 \end{array}\right) 
  = \left( \begin{array}{ccc}
i_u & i_v & i_w \\
j_u & j_v & j_w \\
k_u & k_v & k_w \end{array} \right) 
 \left(\begin{array}{ccc}
 U_i \\
 V_i \\
 W_i \\
 \end{array}\right) +
  \left(\begin{array}{ccc}
 X_0 \\
 Y_0\\
 Z_0 \\
 \end{array}\right) 
\end{equation}

La condición necesaria para que la pose definida por \textbf{i}, \textbf{j}, $x_0$, $y_0$ y $Z_0$ sea la pose exacta se puede expresar en las siguientes ecuaciones: 
\begin{equation}\label{posit_eq2}
\textbf{$M_0M_i$}\frac{f}{Z_0} \textbf{i}=x_i(1+\epsilon_i)-x_0
\end{equation}
\begin{equation}\label{posit_eq3}
\textbf{$M_0M_i$}\frac{f}{Z_0} \textbf{j}=y_i(1+\epsilon_i)-y_0
\end{equation}
donde $\epsilon_i$ se define como
\begin{equation}\label{posit_eq4}
\epsilon_i=\frac{1}{Z_0}\textbf{$M_0M_i$} \cdot \textbf{k}
\end{equation}
Se puede ver que los términos $x_i(1+\epsilon_i)$ y $y_i(1+\epsilon_i)$ son las coordenadas $(x^{'}_i,y^{'}_i)$ de la SOP, en el caso en que la pose está determinada. 

\subsection{Algoritmo}\label{sec:classicPosit4}
Las Ecuaciones \ref{posit_eq2} y \ref{posit_eq3} se puede reescribir como:
\begin{equation}\label{posit_eq8}
\textbf{$M_0M_i$} \textbf{I}=x_i(1+\epsilon_i)-x_0
\end{equation}
\begin{equation}\label{posit_eq9}
\textbf{$M_0M_i$} \textbf{J}=y_i(1+\epsilon_i)-y_0
\end{equation} 
en donde 
\begin{align}
\textbf{I}& = \frac{f}{Z_0}\textbf{i} = s\cdot \textbf{i},&  \textbf{J} = \frac{f}{Z_0}\textbf{j} = s\cdot\textbf{j}
\end{align}


Si se conocieran los valores exactos de los $\epsilon_i$ la pose obtenida de resolver el sistema de ecuaciones sería la pose exacta del objeto, como no se conocen los valores exactos de $\epsilon_i$ se utiliza un método iterativo que converge a la solución buscada. En la primera iteración se le toma $\epsilon_i = 0$. La ecuación para un punto cualquiera está dada por: 
\begin{equation}\label{posit_eq10}
\begin{split}
M_0M_i\cdot\textbf{I} = x^{'}_i - x_0\\
M_0M_j\cdot\textbf{J} = y^{'}_i - y_0
\end{split}
\end{equation}
Si se escribe la Ecuación \ref{posit_eq10} para los $n$ puntos del modelo, se tiene un sistema de $n$ ecuaciones con \textbf{I} y \textbf{J} como incógnitas
  \begin{equation}\label{posit_eq11}
 \begin{split}
 \textbf{A}\textbf{I} = x^{'} - x_0 \\
 \textbf{A}\textbf{J} = y^{'} - y_0
 \end{split}
 \end{equation}
\textbf{A} es una matriz $n\times3$ con las coordenadas de los puntos del modelo $M_i$ en el marco de coordenadas del objeto. Si se tienen más de 4 puntos y no son coplanares, la matriz \textbf{A} es de rango 3, y las soluciones al sistema están dadas por
 \begin{equation}\label{posit_eq12}
 \begin{split}
 \textbf{I} = \textbf{B}\left(x^{'} - x_0\right)\\
 \textbf{J} = \textbf{B}\left(y^{'} - y_0\right)
 \end{split}
 \end{equation}
donde \textbf{B} es la pseudo inversa de la matriz \textbf{A}. Se debe notar que la matriz \textbf{B} depende únicamente de la geometría del modelo que se asume conocida, por lo tanto solo es necesario calcularla una sola vez. 

Una vez obtenidos \textbf{I} y \textbf{J} se calculan \textit{s} y los versores \textbf{i}, \textbf{j} y \textbf{k}
\begin{subequations} \label{posit_eq13}
 \begin{align}
 s& =\left(\vert\textbf{I}\vert \vert\textbf{J}\vert\right)^{1/2} \\
 \textbf{i}& = \frac{\textbf{I}}{s} \\
 \textbf{j}& = \frac{\textbf{J}}{s} \\
 \textbf{k}& = \textbf{i} \times \textbf{j}
 \end{align}
 \end{subequations}
El vector traslación del centro del objeto al centro de la cámara es el vector $OM_0$ 
\begin{equation}\label{posit_eq14}
OM_0 = \frac{Z_0}{f}Om_0 = \frac{Om_0}{s}
\end{equation}
El vector $Om_0$ es conocido ya que se conocen las coordenadas de los puntos $m_i$, en particular $m_0$.

Una vez que se calcularon \textbf{i}, \textbf{j}, \textbf{k} y \textbf{T} se calculan los valores actualizados de $\epsilon_i$ según la Ecuación \ref{posit_eq4}. Si la variación de los $\epsilon_i$ es mayor a un determinado umbral, se repite el procedimiento actualizando las proyecciones SOP en la Ecuación \ref{posit_eq11}, si es menor al umbral se deja de iterar y se guarda la pose calculada.

\subsection{POSIT para puntos coplanares}\label{sec:classicPosit5}

Como se mencionó anteriormente, el algoritmo POSIT no funciona en el caso en que los puntos del modelo pertenecen a un mismo plano. Como los marcadores utilizados son planos, se buscó una versión de POSIT que resuelve el problema de la estimación de pose para este caso. El algoritmo fue escrito por DeMenthon et al. en \cite{CoplanarPosit}.


Si todos los puntos son coplanares, hay dos posibles configuraciones de puntos que cuya proyección SOP es la misma. Esto se puede ver en la Figura \ref{fig: posit_3}.
\begin{figure}[H]
\centering
\includegraphics[scale=0.25]{figs_posit/posit_3.eps}
\caption{Dos objetos dando la misma proyección SOP. Fuente: \cite{CoplanarPosit}.}
\label{fig: posit_3}
\end{figure}

Analíticamente sucede que el sistema de ecuaciones en \ref{posit_eq11} queda de rango 2. El vector solución que se obtiene al realizar la pseudo inversa de \textbf{A} es la proyección de \textbf{I} sobre el plano paralelo al plano imagen ($K$ en la Figura \ref{fig: posit_1}). Para determinar completamente el vector \textbf{I} hace falta calcular coordenada $z$ del vector \textbf{I}. Se procede de manera análoga para calcular el vector \textbf{J}. Finalmente se obtienen dos posibles soluciones. El cálculo detallado de los vectores \textit{I} y \textbf{J} para configuraciones coplanares se puede encontrar en \cite{CoplanarPosit}.   

En el caso en que las dos soluciones sean válidas para todas las iteraciones, el número de poses posibles sería $2^n$ a lo largo de $n$ iteraciones. En la práctica se manejan menos soluciones posibles. Se diferencian dos casos:
\begin{itemize}
\item[$\bullet$] Si se tiene que sólo una de las dos primeras poses calculadas es válida, en las siguientes iteraciones se da mismo comportamiento, por lo que hay solo un camino a seguir.

\item[$\bullet$] Si se tiene que las dos primeras poses calculadas son válidas, se abren dos posibles ramas. En la segunda iteración cada rama da lugar a dos nuevas poses, pero en este caso se toma la pose que da menor error de reproyección.

\end{itemize}

\section{Conclusion}
The conclusion goes here.

\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.


% use section* for acknowledgement
\section*{Acknowledgment}


The authors would like to thank...

\bibliographystyle{IEEEtran}
\bibliography{IEEEfull,articulo}

% that's all folks
\end{document}


